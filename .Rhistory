getwd()
setwd("C:/Users/Michael/SkyDrive/Code/GitHub/DSCapstone/Predictor")
classify=2
classify=function(x)
{1}
tfreq=1
Tfreq=2
tfreq
#setwd("C:/Users/Michael/SkyDrive/Code/GitHub/DSCapstone/Predictor")
library(shiny)
options(shiny.trace = F)  # cahnge to T for trace
library(shinysky)
shinyServer(function(input, output) {
#####################################################
# PRE-PROCESSING #
library(tm)
library(RWeka)
library(data.table)
library(SnowballC)
tfreq=readRDS("t.Tfreq6.RDS")
bfreq=readRDS("b.Tfreq6.RDS")
nfreq=readRDS("n.Tfreq6.RDS")
## FUNCTION DEFINITIONS ##
# Make Corpus and do transformations
makeCorpus<- function(x) {
corpus<-Corpus(VectorSource(x))
# corpus <- tm_map(corpus, stripWhitespace)
corpus <- tm_map(corpus, content_transformer(tolower))
# corpus <- tm_map(corpus, removeWords, stopwords("english"))
corpus <- tm_map(corpus, stemDocument)
corpus<- tm_map(corpus,removePunctuation)
# corpus<- tm_map(corpus,removeNumbers)
return(corpus)
}
process<- function(x) {
# Text Transformations to remove odd characters #
# replace APOSTROPHES OF 2 OR MORE with space - WHY??? that never happens..
# output=lapply(output,FUN= function(x) gsub("'{2}"rr, " ",x))
# Replace numbers with spaces... not sure why to do that yet either.
# output=lapply(output,FUN= function(x) gsub("[0-9]", " ",x))
# Erase commas.
x=gsub(",?", "", x)
# Erase ellipsis
x=gsub("\\.{3,}", "", x)
# Erase colon
x=gsub("\\:", "", x)
# Merge on contractions (apostrophe):
x=gsub("\\'", "", x)
# Erase |:
x=gsub("\\|", "", x)
# Erase {}:
x=gsub("\\{", "", x)
x=gsub("\\}", "", x)
##### SENTENCE SPLITTING AND CLEANUP
# Split into sentences only on single periods or any amount of question marks or exclamation marks and -
# ok here is where you change structure fundamentally...
# Faster if I unlist once? no i guess it keeps getting relisted.
x<-strsplit(unlist(x),"[\\.]{1}")
x<-strsplit(unlist(x),"\\?+")
x<-strsplit(unlist(x),"\\!+")
x<-strsplit(unlist(x),"\\-+")
# Split also on parentheses
x<-strsplit(unlist(x),"\\(+")
x<-strsplit(unlist(x),"\\)+")
# split also on quotation marks
x<-strsplit(unlist(x),"\\\"")
# remove spaces at start and end of sentences:
# HERE is where the problem begins. why?
x<-gsub("^\\s+", "", unlist(x))
x<-gsub("\\s+$", "", unlist(x))
# Replace ~ and any whitespace around with just one space
x<-gsub("\\s*~\\s*", " ", unlist(x))
# Replace forward slash with space
x<-gsub("\\/", " ", unlist(x))
# Replace + signs with space
x<-gsub("\\+", " ", unlist(x))
# it s a
x<-gsub("it s ", "its ", unlist(x))
# 'i m not'
x<-gsub("i m not", "im not", unlist(x))
# 'i didn t'
x<-gsub("i didn t", "i didnt", unlist(x))
# 'i don t'
x<-gsub("i don t", "i dont", unlist(x))
# ' i m '
x<-gsub(" i m ", " im ", unlist(x))
# Eliminate empty and single letter values (more?)
x=x[which(nchar(x)!=1)]
x=x[which(nchar(x)!=0)]
}
classify=function(y){
correct=0
lapply(1:total,FUN=function(x){
# loop through sentence making bigram and answer,
bigram=paste(words[x], words[x+1])
answer=paste(words[x+2])
# then check answer against predicted answer.
# Get answer
Xpred=data.table(y[grep(paste0("^",bigram," "),y$grams),][order(-counts)])
# isolate the answer from prediction table.
Xpred=unlist(strsplit(Xpred[1]$grams,"\\s+"))
Xpred=Xpred[length(Xpred)]
# Test equality of prediction to actual and counter for the accuracy measure
if(!is.na(Xpred)){
if(Xpred==answer){correct=correct+1}
correct<<-correct
}
})
accuracy = correct/total
return(accuracy)
}
#### INPUT MUNGING ####
getPred=function(x){
# Take an input:
test=x
# transform as training set was (lowercase, stem, strip punctuation etc.)
test=iconv(test, to='ASCII', sub=' ')
test=process(test)
test=paste0(test, collapse=" ")
corpus<-makeCorpus(test)
corpus=as.character(corpus[[1]][1])
# Split by words:
words<-unlist(strsplit(corpus,"\\s+"))
# Classify text (if 3 words or more)
total=length(words)-2
if(length(words)>=3){
b.acc=classify(bfreq)
t.acc=classify(tfreq)
n.acc=classify(nfreq)
}
# Select frequency table based on classication results.
if(b.acc>t.acc && b.acc>n.acc){
Tfreq=bfreq
}
if(t.acc>b.acc && t.acc>n.acc){
Tfreq=tfreq
}
if(n.acc>b.acc && n.acc>t.acc){
Tfreq=nfreq
}
# Isolate last two words of the sentence
history=words[(length(words)-1):length(words)]
nMin1=words[length(words)]
history=paste(as.character(history),collapse=' ')
# Make prediction list of matches:
Tpred=data.table(Tfreq[grep(paste0("^",history," "),Tfreq$grams),][order(-counts)])
# Isolate top prediction:
pred=Tpred[1]$grams
pred=unlist(strsplit(pred,"\\s+"))
pred=pred[length(pred)]
}
#####################################################
# OUTPUT PREDICTION #
output$prediction <- renderText({
as.character(getPred(input$text))
})
})
shiny::runApp()
shiny::runApp()
shiny::runApp()
#setwd("C:/Users/Michael/SkyDrive/Code/GitHub/DSCapstone/Predictor")
library(shiny)
options(shiny.trace = F)  # cahnge to T for trace
library(shinysky)
shinyServer(function(input, output) {
#####################################################
# PRE-PROCESSING #
library(tm)
library(RWeka)
library(data.table)
library(SnowballC)
tfreq=readRDS("t.Tfreq6.RDS")
bfreq=readRDS("b.Tfreq4.RDS")
nfreq=readRDS("n.Tfreq4.RDS")
## FUNCTION DEFINITIONS ##
# Make Corpus and do transformations
makeCorpus<- function(x) {
corpus<-Corpus(VectorSource(x))
# corpus <- tm_map(corpus, stripWhitespace)
corpus <- tm_map(corpus, content_transformer(tolower))
# corpus <- tm_map(corpus, removeWords, stopwords("english"))
corpus <- tm_map(corpus, stemDocument)
corpus<- tm_map(corpus,removePunctuation)
# corpus<- tm_map(corpus,removeNumbers)
return(corpus)
}
process<- function(x) {
# Text Transformations to remove odd characters #
# replace APOSTROPHES OF 2 OR MORE with space - WHY??? that never happens..
# output=lapply(output,FUN= function(x) gsub("'{2}"rr, " ",x))
# Replace numbers with spaces... not sure why to do that yet either.
# output=lapply(output,FUN= function(x) gsub("[0-9]", " ",x))
# Erase commas.
x=gsub(",?", "", x)
# Erase ellipsis
x=gsub("\\.{3,}", "", x)
# Erase colon
x=gsub("\\:", "", x)
# Merge on contractions (apostrophe):
x=gsub("\\'", "", x)
# Erase |:
x=gsub("\\|", "", x)
# Erase {}:
x=gsub("\\{", "", x)
x=gsub("\\}", "", x)
##### SENTENCE SPLITTING AND CLEANUP
# Split into sentences only on single periods or any amount of question marks or exclamation marks and -
# ok here is where you change structure fundamentally...
# Faster if I unlist once? no i guess it keeps getting relisted.
x<-strsplit(unlist(x),"[\\.]{1}")
x<-strsplit(unlist(x),"\\?+")
x<-strsplit(unlist(x),"\\!+")
x<-strsplit(unlist(x),"\\-+")
# Split also on parentheses
x<-strsplit(unlist(x),"\\(+")
x<-strsplit(unlist(x),"\\)+")
# split also on quotation marks
x<-strsplit(unlist(x),"\\\"")
# remove spaces at start and end of sentences:
# HERE is where the problem begins. why?
x<-gsub("^\\s+", "", unlist(x))
x<-gsub("\\s+$", "", unlist(x))
# Replace ~ and any whitespace around with just one space
x<-gsub("\\s*~\\s*", " ", unlist(x))
# Replace forward slash with space
x<-gsub("\\/", " ", unlist(x))
# Replace + signs with space
x<-gsub("\\+", " ", unlist(x))
# it s a
x<-gsub("it s ", "its ", unlist(x))
# 'i m not'
x<-gsub("i m not", "im not", unlist(x))
# 'i didn t'
x<-gsub("i didn t", "i didnt", unlist(x))
# 'i don t'
x<-gsub("i don t", "i dont", unlist(x))
# ' i m '
x<-gsub(" i m ", " im ", unlist(x))
# Eliminate empty and single letter values (more?)
x=x[which(nchar(x)!=1)]
x=x[which(nchar(x)!=0)]
}
classify=function(y){
total=length(words)-2
correct=0
lapply(1:total,FUN=function(x){
# loop through sentence making bigram and answer,
bigram=paste(words[x], words[x+1])
answer=paste(words[x+2])
# then check answer against predicted answer.
# Get answer
Xpred=data.table(y[grep(paste0("^",bigram," "),y$grams),][order(-counts)])
# isolate the answer from prediction table.
Xpred=unlist(strsplit(Xpred[1]$grams,"\\s+"))
Xpred=Xpred[length(Xpred)]
# Test equality of prediction to actual and counter for the accuracy measure
if(!is.na(Xpred)){
if(Xpred==answer){correct=correct+1}
correct<<-correct
}
})
accuracy = correct/total
return(accuracy)
}
#### INPUT MUNGING ####
getPred=function(x){
# Take an input:
test=x
# transform as training set was (lowercase, stem, strip punctuation etc.)
test=iconv(test, to='ASCII', sub=' ')
test=process(test)
test=paste0(test, collapse=" ")
corpus<-makeCorpus(test)
corpus=as.character(corpus[[1]][1])
# Split by words:
words<-unlist(strsplit(corpus,"\\s+"))
# Classify text (if 3 words or more)
if(length(words)>=3){
b.acc=classify(bfreq)
t.acc=classify(tfreq)
n.acc=classify(nfreq)
}
# Select frequency table based on classication results.
if(b.acc>t.acc && b.acc>n.acc){
Tfreq=bfreq
}
if(t.acc>b.acc && t.acc>n.acc){
Tfreq=tfreq
}
if(n.acc>b.acc && n.acc>t.acc){
Tfreq=nfreq
}
# Isolate last two words of the sentence
history=words[(length(words)-1):length(words)]
nMin1=words[length(words)]
history=paste(as.character(history),collapse=' ')
# Make prediction list of matches:
Tpred=data.table(Tfreq[grep(paste0("^",history," "),Tfreq$grams),][order(-counts)])
# Isolate top prediction:
pred=Tpred[1]$grams
pred=unlist(strsplit(pred,"\\s+"))
pred=pred[length(pred)]
}
#####################################################
# OUTPUT PREDICTION #
output$prediction <- renderText({
as.character(getPred(input$text))
})
})
makeCorpus<- function(x) {
corpus<-Corpus(VectorSource(x))
# corpus <- tm_map(corpus, stripWhitespace)
corpus <- tm_map(corpus, content_transformer(tolower))
# corpus <- tm_map(corpus, removeWords, stopwords("english"))
corpus <- tm_map(corpus, stemDocument)
corpus<- tm_map(corpus,removePunctuation)
# corpus<- tm_map(corpus,removeNumbers)
return(corpus)
}
tfreq=readRDS("t.Tfreq6.RDS")
bfreq=readRDS("b.Tfreq4.RDS")
nfreq=readRDS("n.Tfreq4.RDS")
process<- function(x) {
# Text Transformations to remove odd characters #
# replace APOSTROPHES OF 2 OR MORE with space - WHY??? that never happens..
# output=lapply(output,FUN= function(x) gsub("'{2}"rr, " ",x))
# Replace numbers with spaces... not sure why to do that yet either.
# output=lapply(output,FUN= function(x) gsub("[0-9]", " ",x))
# Erase commas.
x=gsub(",?", "", x)
# Erase ellipsis
x=gsub("\\.{3,}", "", x)
# Erase colon
x=gsub("\\:", "", x)
# Merge on contractions (apostrophe):
x=gsub("\\'", "", x)
# Erase |:
x=gsub("\\|", "", x)
# Erase {}:
x=gsub("\\{", "", x)
x=gsub("\\}", "", x)
##### SENTENCE SPLITTING AND CLEANUP
# Split into sentences only on single periods or any amount of question marks or exclamation marks and -
# ok here is where you change structure fundamentally...
# Faster if I unlist once? no i guess it keeps getting relisted.
x<-strsplit(unlist(x),"[\\.]{1}")
x<-strsplit(unlist(x),"\\?+")
x<-strsplit(unlist(x),"\\!+")
x<-strsplit(unlist(x),"\\-+")
# Split also on parentheses
x<-strsplit(unlist(x),"\\(+")
x<-strsplit(unlist(x),"\\)+")
# split also on quotation marks
x<-strsplit(unlist(x),"\\\"")
# remove spaces at start and end of sentences:
# HERE is where the problem begins. why?
x<-gsub("^\\s+", "", unlist(x))
x<-gsub("\\s+$", "", unlist(x))
# Replace ~ and any whitespace around with just one space
x<-gsub("\\s*~\\s*", " ", unlist(x))
# Replace forward slash with space
x<-gsub("\\/", " ", unlist(x))
# Replace + signs with space
x<-gsub("\\+", " ", unlist(x))
# it s a
x<-gsub("it s ", "its ", unlist(x))
# 'i m not'
x<-gsub("i m not", "im not", unlist(x))
# 'i didn t'
x<-gsub("i didn t", "i didnt", unlist(x))
# 'i don t'
x<-gsub("i don t", "i dont", unlist(x))
# ' i m '
x<-gsub(" i m ", " im ", unlist(x))
# Eliminate empty and single letter values (more?)
x=x[which(nchar(x)!=1)]
x=x[which(nchar(x)!=0)]
}
classify=function(y){
total=length(words)-2
correct=0
lapply(1:total,FUN=function(x){
# loop through sentence making bigram and answer,
bigram=paste(words[x], words[x+1])
answer=paste(words[x+2])
# then check answer against predicted answer.
# Get answer
Xpred=data.table(y[grep(paste0("^",bigram," "),y$grams),][order(-counts)])
# isolate the answer from prediction table.
Xpred=unlist(strsplit(Xpred[1]$grams,"\\s+"))
Xpred=Xpred[length(Xpred)]
# Test equality of prediction to actual and counter for the accuracy measure
if(!is.na(Xpred)){
if(Xpred==answer){correct=correct+1}
correct<<-correct
}
})
accuracy = correct/total
return(accuracy)
}
#### INPUT MUNGING ####
getPred=function(x){
# Take an input:
test=x
# transform as training set was (lowercase, stem, strip punctuation etc.)
test=iconv(test, to='ASCII', sub=' ')
test=process(test)
test=paste0(test, collapse=" ")
corpus<-makeCorpus(test)
corpus=as.character(corpus[[1]][1])
# Split by words:
words<-unlist(strsplit(corpus,"\\s+"))
# Classify text (if 3 words or more)
if(length(words)>=3){
b.acc=classify(bfreq)
t.acc=classify(tfreq)
n.acc=classify(nfreq)
}
# Select frequency table based on classication results.
if(b.acc>t.acc && b.acc>n.acc){
Tfreq=bfreq
}
if(t.acc>b.acc && t.acc>n.acc){
Tfreq=tfreq
}
if(n.acc>b.acc && n.acc>t.acc){
Tfreq=nfreq
}
# Isolate last two words of the sentence
history=words[(length(words)-1):length(words)]
nMin1=words[length(words)]
history=paste(as.character(history),collapse=' ')
# Make prediction list of matches:
Tpred=data.table(Tfreq[grep(paste0("^",history," "),Tfreq$grams),][order(-counts)])
# Isolate top prediction:
pred=Tpred[1]$grams
pred=unlist(strsplit(pred,"\\s+"))
pred=pred[length(pred)]
}
#####################################################
# OUTPUT PREDICTION #
output$prediction <- renderText({
as.character(getPred(input$text))
})
})
input="When you breathe, I want to be the air for you. I'll be there for you, I'd live and I'd"
getPred(input)
test=input
test
test=iconv(test, to='ASCII', sub=' ')
test=process(test)
test=paste0(test, collapse=" ")
corpus<-makeCorpus(test)
corpus=as.character(corpus[[1]][1])
corpus
words<-unlist(strsplit(corpus,"\\s+"))
words
if(length(words)>=3){
b.acc=classify(bfreq)
t.acc=classify(tfreq)
n.acc=classify(nfreq)
}
classify=function(y,words=words){
total=length(words)-2
correct=0
lapply(1:total,FUN=function(x){
# loop through sentence making bigram and answer,
bigram=paste(words[x], words[x+1])
answer=paste(words[x+2])
# then check answer against predicted answer.
# Get answer
Xpred=data.table(y[grep(paste0("^",bigram," "),y$grams),][order(-counts)])
# isolate the answer from prediction table.
Xpred=unlist(strsplit(Xpred[1]$grams,"\\s+"))
Xpred=Xpred[length(Xpred)]
# Test equality of prediction to actual and counter for the accuracy measure
if(!is.na(Xpred)){
if(Xpred==answer){correct=correct+1}
correct<<-correct
}
})
accuracy = correct/total
return(accuracy)
}
getPred(input)
classify=function(y,words.=words){
total=length(words.)-2
correct=0
lapply(1:total,FUN=function(x){
# loop through sentence making bigram and answer,
bigram=paste(words.[x], words.[x+1])
answer=paste(words.[x+2])
# then check answer against predicted answer.
# Get answer
Xpred=data.table(y[grep(paste0("^",bigram," "),y$grams),][order(-counts)])
# isolate the answer from prediction table.
Xpred=unlist(strsplit(Xpred[1]$grams,"\\s+"))
Xpred=Xpred[length(Xpred)]
# Test equality of prediction to actual and counter for the accuracy measure
if(!is.na(Xpred)){
if(Xpred==answer){correct=correct+1}
correct<<-correct
}
})
accuracy = correct/total
return(accuracy)
}
getPred(input)
shiny::runApp()
strsplit("test!hey","\\!+")
strsplit("test!hey","!+")
shiny::runApp()
